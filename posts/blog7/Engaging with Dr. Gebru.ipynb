{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f03613",
   "metadata": {},
   "source": [
    "# Engaging with Dr. Timnit Gebru\n",
    "## Kate Kenny \n",
    "### CS 0451 \n",
    "\n",
    "This week, our machine learning class has the opportunity to hear from Dr. Timnit Gebru, a leader in the field of algorithmic bias. Dr. Gebru is the founder of the Distributed Artificial Intelligence Research Institute (DAIR) and the co-founder of Black in AI. Her work gained national attention after she left Google, where she co-lead the Ethical Artificial Intelligence Team, after the company had issues with a paper she co-authored on the dangers of large language models. She is the recipient of numerous awards and accolades for her work on bias both within technologies and within tech companies. I am very excited and thankful for the opportunity to speak with her in our class setting and to hear her speak to a broader audience at the college on Monday evening. \n",
    "\n",
    "## Dr. Gebru's Talk: Fairness, Accountaility, Transparency, and Ethics in Computer Vision\n",
    "\n",
    "   Dr. Gebru states that the motivation for this talk was so much of the harm that has been done to Black Americans both through broad institutional racism and through the specific technologies that have been created without Black voices in the room. She states that this is a difficult topic for her, as a Black woman, to discuss in Computer Vision spaces since they are overwhelmingly white and male. She begins with the point that many people developing computer vision technology have hopes and concerns about the uses of these technologies but do not actually know what they are doing in practice. \n",
    "   \n",
    "   Gebru states that the same techology will have different pros and cons to people coming from different backgrounds. Surviellance is one example of this, as people who are used to being in heavily survielled areas might immediately threats of computer vision that would not occus to people unfamiliar to such surviellance. Dr. Gebru gives many examples of technologies and startups that using photos or videos, filter or classify people in ways that perpetuate systemic racism and other inequalities. She gives examples in policing systems, automated hiring/interview technologies, and crime predictors based on facial features. \n",
    "   \n",
    "   A major theme throughout the talk is that the work done by computer scientists is not abstract, but rather about and impacting real people. Additionally, there can be algorithms or technologies that work exactly as intented but still perpetuate systemic inequalities and have the largest impacts on already marginalized groups. Gebru asserts that people are often willing to recognize that datasets need to be more diverse but ignore systemic issues behind these systems. People are eager to make things more diverse without thinking critically about whether things like gender recognition or other facial recognition software are necessary or ethical. \n",
    "   \n",
    "   \n",
    "tldr: Making technology fair goes beyond creating technologies that work equally well on everyone. Every technology and data set involves real people on both sides and can perpetuate systemic biases or violate civil liberties despite how well they work in quantitative measures as technology can only amplify an human intent or issues. \n",
    "\n",
    "## Question \n",
    "How do you think the public panic around things like Chat GPT and other similar recent AI systems has obscured the real dangers you discussed in the talk? Is this cultural moment an opportunity to engage the public on these issues since there is a growing discussion around the dangers of AI or are broader issues being ignored in this discussion? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
